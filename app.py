{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3364d9a2-bc33-48a8-a9dc-e0d7a1e506e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=5tobHzkf-uAC2aJVxI3Jo9x-1jbAplaEQkhMHJKlOCg&tc=0ehGkjO8IWJtG96aIpKGbxassrFeifSRRj5yXB636To&cc=jwpgxLN8pqDtbxY2OCPIinNU8WnjYg0NFuopd1lWDt8>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=5tobHzkf-uAC2aJVxI3Jo9x-1jbAplaEQkhMHJKlOCg&tc=0ehGkjO8IWJtG96aIpKGbxassrFeifSRRj5yXB636To&cc=jwpgxLN8pqDtbxY2OCPIinNU8WnjYg0NFuopd1lWDt8</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter verification code:  4/1AQSTgQFXv9QRWZx1SKF0w6RU8k4wjZ1CJXuNVNvvrKTuVaiFH52rZXMOvuo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "ee.Authenticate()  # Run once interactively to set up credentials.\n",
    "ee.Initialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc158abb-9fa2-4eb1-a18b-84d53fd0be5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98b5962f-5179-44d7-b693-edc7b3e008ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing global land cover data...\n",
      "Processing global burn date data...\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='0.0.0.0', port=8051): Max retries exceeded with url: /_alive_b6c1894c-8d6d-46fc-be50-3e04d3cf465c (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000196C7DD89B0>: Failed to establish a new connection: [WinError 10049] The requested address is not valid in its context'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:196\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m     sock \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    197\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport),\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[0;32m    199\u001b[0m         source_address\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_address,\n\u001b[0;32m    200\u001b[0m         socket_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket_options,\n\u001b[0;32m    201\u001b[0m     )\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m sock\u001b[38;5;241m.\u001b[39mconnect(sa)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 10049] The requested address is not valid in its context",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    790\u001b[0m     conn,\n\u001b[0;32m    791\u001b[0m     method,\n\u001b[0;32m    792\u001b[0m     url,\n\u001b[0;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    802\u001b[0m )\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:495\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 495\u001b[0m     conn\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    496\u001b[0m         method,\n\u001b[0;32m    497\u001b[0m         url,\n\u001b[0;32m    498\u001b[0m         body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    499\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    500\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    501\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    502\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    503\u001b[0m         enforce_content_length\u001b[38;5;241m=\u001b[39menforce_content_length,\n\u001b[0;32m    504\u001b[0m     )\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:398\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[1;32m--> 398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders()\n\u001b[0;32m    400\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1091\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1091\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1094\u001b[0m \n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1035\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m-> 1035\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:236\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_conn()\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:211\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    213\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;66;03m# Audit hooks are only available in Python 3.8+\u001b[39;00m\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x00000196C7DD89B0>: Failed to establish a new connection: [WinError 10049] The requested address is not valid in its context",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:589\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 589\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    590\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    591\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    592\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    593\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    594\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    595\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    596\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    597\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    598\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    599\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    600\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    601\u001b[0m     )\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:843\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    841\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 843\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[0;32m    844\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39mnew_e, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    845\u001b[0m )\n\u001b[0;32m    846\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[1;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='0.0.0.0', port=8051): Max retries exceeded with url: /_alive_b6c1894c-8d6d-46fc-be50-3e04d3cf465c (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000196C7DD89B0>: Failed to establish a new connection: [WinError 10049] The requested address is not valid in its context'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 402\u001b[0m\n\u001b[0;32m    399\u001b[0m     app\u001b[38;5;241m.\u001b[39mrun_server(debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, host\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0.0.0.0\u001b[39m\u001b[38;5;124m'\u001b[39m, port\u001b[38;5;241m=\u001b[39mport)\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 402\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[9], line 399\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;124;03mMain entry point for the Dash application.\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    398\u001b[0m port \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPORT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m8051\u001b[39m))\n\u001b[1;32m--> 399\u001b[0m app\u001b[38;5;241m.\u001b[39mrun_server(debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, host\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0.0.0.0\u001b[39m\u001b[38;5;124m'\u001b[39m, port\u001b[38;5;241m=\u001b[39mport)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dash\\dash.py:2287\u001b[0m, in \u001b[0;36mDash.run_server\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2277\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"`run_server` is a deprecated alias of `run` and may be removed in a\u001b[39;00m\n\u001b[0;32m   2278\u001b[0m \u001b[38;5;124;03mfuture version. We recommend using `app.run` instead.\u001b[39;00m\n\u001b[0;32m   2279\u001b[0m \n\u001b[0;32m   2280\u001b[0m \u001b[38;5;124;03mSee `app.run` for usage information.\u001b[39;00m\n\u001b[0;32m   2281\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2282\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2283\u001b[0m     \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(\n\u001b[0;32m   2284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDash.run_server is deprecated and will be removed in Dash 3.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2285\u001b[0m     )\n\u001b[0;32m   2286\u001b[0m )\n\u001b[1;32m-> 2287\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dash\\dash.py:2173\u001b[0m, in \u001b[0;36mDash.run\u001b[1;34m(self, host, port, proxy, debug, jupyter_mode, jupyter_width, jupyter_height, jupyter_server_url, dev_tools_ui, dev_tools_props_check, dev_tools_serve_dev_bundles, dev_tools_hot_reload, dev_tools_hot_reload_interval, dev_tools_hot_reload_watch_interval, dev_tools_hot_reload_max_retry, dev_tools_silence_routes_logging, dev_tools_prune_errors, **flask_run_options)\u001b[0m\n\u001b[0;32m   2170\u001b[0m             extra_files\u001b[38;5;241m.\u001b[39mappend(path)\n\u001b[0;32m   2172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m jupyter_dash\u001b[38;5;241m.\u001b[39mactive:\n\u001b[1;32m-> 2173\u001b[0m     jupyter_dash\u001b[38;5;241m.\u001b[39mrun_app(\n\u001b[0;32m   2174\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2175\u001b[0m         mode\u001b[38;5;241m=\u001b[39mjupyter_mode,\n\u001b[0;32m   2176\u001b[0m         width\u001b[38;5;241m=\u001b[39mjupyter_width,\n\u001b[0;32m   2177\u001b[0m         height\u001b[38;5;241m=\u001b[39mjupyter_height,\n\u001b[0;32m   2178\u001b[0m         host\u001b[38;5;241m=\u001b[39mhost,\n\u001b[0;32m   2179\u001b[0m         port\u001b[38;5;241m=\u001b[39mport,\n\u001b[0;32m   2180\u001b[0m         server_url\u001b[38;5;241m=\u001b[39mjupyter_server_url,\n\u001b[0;32m   2181\u001b[0m     )\n\u001b[0;32m   2182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver\u001b[38;5;241m.\u001b[39mrun(host\u001b[38;5;241m=\u001b[39mhost, port\u001b[38;5;241m=\u001b[39mport, debug\u001b[38;5;241m=\u001b[39mdebug, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflask_run_options)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dash\\_jupyter.py:405\u001b[0m, in \u001b[0;36mJupyterDash.run_app\u001b[1;34m(self, app, mode, width, height, host, port, server_url)\u001b[0m\n\u001b[0;32m    403\u001b[0m     display(HTML(msg))\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 405\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_error\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dash\\_jupyter.py:392\u001b[0m, in \u001b[0;36mJupyterDash.run_app\u001b[1;34m(self, app, mode, width, height, host, port, server_url)\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 392\u001b[0m     wait_for_app()\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_colab:\n\u001b[0;32m    395\u001b[0m         JupyterDash\u001b[38;5;241m.\u001b[39m_display_in_colab(dashboard_url, port, mode, width, height)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\retrying.py:56\u001b[0m, in \u001b[0;36mretry.<locals>.wrap.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;129m@six\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Retrying(\u001b[38;5;241m*\u001b[39mdargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdkw)\u001b[38;5;241m.\u001b[39mcall(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\retrying.py:266\u001b[0m, in \u001b[0;36mRetrying.call\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop(attempt_number, delay_since_first_attempt_ms):\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_exception \u001b[38;5;129;01mand\u001b[39;00m attempt\u001b[38;5;241m.\u001b[39mhas_exception:\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;66;03m# get() on an attempt with an exception should cause it to be raised, but raise just in case\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m attempt\u001b[38;5;241m.\u001b[39mget()\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RetryError(attempt)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\retrying.py:301\u001b[0m, in \u001b[0;36mAttempt.get\u001b[1;34m(self, wrap_exception)\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RetryError(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 301\u001b[0m         six\u001b[38;5;241m.\u001b[39mreraise(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\six.py:719\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[0;32m    718\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 719\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[0;32m    720\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    721\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\retrying.py:251\u001b[0m, in \u001b[0;36mRetrying.call\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_before_attempts(attempt_number)\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 251\u001b[0m     attempt \u001b[38;5;241m=\u001b[39m Attempt(fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs), attempt_number, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     tb \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dash\\_jupyter.py:389\u001b[0m, in \u001b[0;36mJupyterDash.run_app.<locals>.wait_for_app\u001b[1;34m()\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mConnectionError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    388\u001b[0m     _get_error()\n\u001b[1;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dash\\_jupyter.py:376\u001b[0m, in \u001b[0;36mJupyterDash.run_app.<locals>.wait_for_app\u001b[1;34m()\u001b[0m\n\u001b[0;32m    374\u001b[0m _get_error()\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 376\u001b[0m     req \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(alive_url)\n\u001b[0;32m    377\u001b[0m     res \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mdecode()\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m req\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, params\u001b[38;5;241m=\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:622\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[0;32m    619\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[0;32m    620\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m--> 622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPConnectionPool(host='0.0.0.0', port=8051): Max retries exceeded with url: /_alive_b6c1894c-8d6d-46fc-be50-3e04d3cf465c (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000196C7DD89B0>: Failed to establish a new connection: [WinError 10049] The requested address is not valid in its context'))"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Wildfire Analysis Dashboard\n",
    "---------------------------\n",
    "\n",
    "This application analyses wildfire data in Algeria (2001-2020) by processing\n",
    "land cover and burn date data, then displays the results via an interactive\n",
    "dashboard built with Plotly Dash.\n",
    "\n",
    "Tasks performed:\n",
    "    1. Validate that the required data files exist.\n",
    "    2. Process global land cover data and burn date data.\n",
    "    3. Compute province-specific statistics.\n",
    "    4. Build an interactive dashboard to visualise wildfire-related metrics.\n",
    "\n",
    "Requirements:\n",
    "    - dash\n",
    "    - plotly\n",
    "    - rasterio\n",
    "    - numpy\n",
    "    - pandas\n",
    "    - geopandas\n",
    "    - rasterstats\n",
    "\n",
    "Author: [Your Name]\n",
    "Date: [YYYY-MM-DD]\n",
    "License: [Appropriate License]\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from rasterstats import zonal_stats\n",
    "\n",
    "# ----------------------- Constants and File Paths -------------------------\n",
    "PROVINCES_PATH = r'C:\\Users\\lenovo legion\\Documents\\ArcGIS data\\DZ\\frontiere\\dza_admbnda_adm1_unhcr_20200120.shp'\n",
    "LANDCOVER_TEMPLATE = r'C:\\Users\\lenovo legion\\Desktop\\Datasets\\LandCover_Exports\\LandCover_Summer_{year}_95Percent_Confidence.tif'\n",
    "BURNDATE_TEMPLATE = r'C:\\Users\\lenovo legion\\Desktop\\Datasets\\BurnDate_Exports\\BurnDate_Summer_{year}_95Percent_Confidence.tif'\n",
    "START_YEAR = 2001\n",
    "END_YEAR = 2020  # inclusive\n",
    "PIXEL_AREA = 250 * 250 / 1e6  # km² per pixel\n",
    "\n",
    "# Load administrative boundaries\n",
    "provinces = gpd.read_file(PROVINCES_PATH)\n",
    "\n",
    "# ----------------------- File Validation -------------------------\n",
    "def validate_files():\n",
    "    \"\"\"\n",
    "    Validate that all required land cover and burn date files exist.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If one or more required files are missing.\n",
    "    \"\"\"\n",
    "    missing = []\n",
    "    for year in range(START_YEAR, END_YEAR + 1):\n",
    "        lc_path = LANDCOVER_TEMPLATE.format(year=year)\n",
    "        bd_path = BURNDATE_TEMPLATE.format(year=year)\n",
    "        if not os.path.exists(lc_path):\n",
    "            missing.append(lc_path)\n",
    "        if not os.path.exists(bd_path):\n",
    "            missing.append(bd_path)\n",
    "    if missing:\n",
    "        raise FileNotFoundError(f\"Missing {len(missing)} file(s):\\n\" + \"\\n\".join(missing))\n",
    "\n",
    "validate_files()\n",
    "\n",
    "# ----------------------- Global Data Processing -------------------------\n",
    "def process_landcover_burns() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process global land cover data for each year by reclassifying pixel values into\n",
    "    aggregated land cover groups and computing burned area.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Annual data with burned area (km²) for 'Forest', 'Cropland', and 'Shrubland'.\n",
    "    \"\"\"\n",
    "    annual_data = []\n",
    "    reclass_map = {\n",
    "        10: \"Cropland\", 20: \"Cropland\", 30: \"Cropland\", 40: \"Cropland\",\n",
    "        50: \"Forest\", 60: \"Forest\", 70: \"Forest\", 80: \"Forest\",\n",
    "        90: \"Forest\", 100: \"Forest\", 110: \"Forest\",\n",
    "        120: \"Shrubland\", 130: \"Shrubland\", 140: \"Shrubland\", 150: \"Shrubland\",\n",
    "        170: \"Forest\", 180: \"Shrubland\"\n",
    "    }\n",
    "    for year in range(START_YEAR, END_YEAR + 1):\n",
    "        file_path = LANDCOVER_TEMPLATE.format(year=year)\n",
    "        with rasterio.open(file_path) as src:\n",
    "            data = src.read(1)\n",
    "            valid_mask = data != 0\n",
    "        class_counts = np.bincount(data[valid_mask].flatten(), minlength=181)\n",
    "        record = {\"Year\": year, \"Forest\": 0.0, \"Cropland\": 0.0, \"Shrubland\": 0.0}\n",
    "        for code, group in reclass_map.items():\n",
    "            count = class_counts[code] if code < len(class_counts) else 0\n",
    "            record[group] += count * PIXEL_AREA\n",
    "        annual_data.append(record)\n",
    "    return pd.DataFrame(annual_data)\n",
    "\n",
    "def process_burndates() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process global burn date data by extracting the day-of-year values from burn date rasters.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing 'day_of_year' and 'year' columns.\n",
    "    \"\"\"\n",
    "    all_dates = []\n",
    "    for year in range(START_YEAR, END_YEAR + 1):\n",
    "        file_path = BURNDATE_TEMPLATE.format(year=year)\n",
    "        with rasterio.open(file_path) as src:\n",
    "            data = src.read(1)\n",
    "            dates = data[data > 0].flatten()\n",
    "        df = pd.DataFrame({'day_of_year': dates})\n",
    "        df['year'] = year\n",
    "        all_dates.append(df)\n",
    "    return pd.concat(all_dates, ignore_index=True)\n",
    "\n",
    "print(\"Processing global land cover data...\")\n",
    "landcover_df = process_landcover_burns()\n",
    "print(\"Processing global burn date data...\")\n",
    "burndate_df = process_burndates()\n",
    "\n",
    "# ----------------------- Province-Specific Data Functions -------------------------\n",
    "def get_province_landcover(province_geom) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For a given province geometry, compute annual burned area per aggregated land cover group.\n",
    "\n",
    "    Args:\n",
    "        province_geom: Geometry of the province.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Annual data for the province with burned area for each land cover group.\n",
    "    \"\"\"\n",
    "    reclass_map = {\n",
    "        10: \"Cropland\", 20: \"Cropland\", 30: \"Cropland\", 40: \"Cropland\",\n",
    "        50: \"Forest\", 60: \"Forest\", 70: \"Forest\", 80: \"Forest\",\n",
    "        90: \"Forest\", 100: \"Forest\", 110: \"Forest\",\n",
    "        120: \"Shrubland\", 130: \"Shrubland\", 140: \"Shrubland\", 150: \"Shrubland\",\n",
    "        170: \"Forest\", 180: \"Shrubland\"\n",
    "    }\n",
    "    records = []\n",
    "    for year in range(START_YEAR, END_YEAR + 1):\n",
    "        file_path = LANDCOVER_TEMPLATE.format(year=year)\n",
    "        with rasterio.open(file_path) as src:\n",
    "            # Reproject province geometry to raster CRS\n",
    "            geom_proj = gpd.GeoSeries([province_geom], crs=provinces.crs).to_crs(src.crs).iloc[0]\n",
    "            try:\n",
    "                out_image, _ = rasterio.mask.mask(src, [geom_proj], crop=True)\n",
    "            except Exception:\n",
    "                continue\n",
    "            data = out_image[0]\n",
    "            valid_mask = data != 0\n",
    "        record = {\"Year\": year, \"Forest\": 0.0, \"Cropland\": 0.0, \"Shrubland\": 0.0}\n",
    "        if np.any(valid_mask):\n",
    "            class_counts = np.bincount(data[valid_mask].flatten(), minlength=181)\n",
    "        else:\n",
    "            class_counts = np.zeros(181, dtype=int)\n",
    "        for code, group in reclass_map.items():\n",
    "            count = class_counts[code] if code < len(class_counts) else 0\n",
    "            record[group] += count * PIXEL_AREA\n",
    "        records.append(record)\n",
    "    return pd.DataFrame(records) if records else pd.DataFrame(columns=[\"Year\", \"Forest\", \"Cropland\", \"Shrubland\"])\n",
    "\n",
    "def get_province_burndates(province_geom) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For a given province geometry, extract burn date pixel values by year.\n",
    "\n",
    "    Args:\n",
    "        province_geom: Geometry of the province.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with burn dates (day_of_year) and corresponding year.\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    for year in range(START_YEAR, END_YEAR + 1):\n",
    "        file_path = BURNDATE_TEMPLATE.format(year=year)\n",
    "        with rasterio.open(file_path) as src:\n",
    "            geom_proj = gpd.GeoSeries([province_geom], crs=provinces.crs).to_crs(src.crs).iloc[0]\n",
    "            try:\n",
    "                out_image, _ = rasterio.mask.mask(src, [geom_proj], crop=True)\n",
    "            except Exception:\n",
    "                continue\n",
    "            data = out_image[0]\n",
    "            valid = data > 0\n",
    "            if np.any(valid):\n",
    "                dates = data[valid].flatten()\n",
    "                df = pd.DataFrame({'day_of_year': dates})\n",
    "                df['year'] = year\n",
    "                frames.append(df)\n",
    "    return pd.concat(frames, ignore_index=True) if frames else pd.DataFrame(columns=['day_of_year', 'year'])\n",
    "\n",
    "# ----------------------- Dashboard Layout -------------------------\n",
    "app = dash.Dash(__name__)\n",
    "app.title = \"Algeria Wildfire Analysis (2001-2020)\"\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Algeria Wildfire Analysis (2001-2020)\",\n",
    "            style={'textAlign': 'center', 'color': '#2c3e50'}),\n",
    "    \n",
    "    # Year Dropdown: \"Total\" (aggregated) or a specific year.\n",
    "    html.Div([\n",
    "        html.Label(\"Select Year for Map:\"),\n",
    "        dcc.Dropdown(\n",
    "            id='year-dropdown',\n",
    "            options=[{'label': 'Total', 'value': 'total'}] +\n",
    "                    [{'label': str(year), 'value': year} for year in range(START_YEAR, END_YEAR + 1)],\n",
    "            value='total',\n",
    "            clearable=False,\n",
    "            style={'width': '200px'}\n",
    "        )\n",
    "    ], style={'textAlign': 'center', 'padding': '10px'}),\n",
    "    \n",
    "    # Global map display\n",
    "    dcc.Graph(id='province-map'),\n",
    "    html.Div(id='map-status', style={'textAlign': 'center', 'color': '#7f8c8d', 'padding': '10px'}),\n",
    "    \n",
    "    html.Hr(),\n",
    "    \n",
    "    # Charts: Land cover analysis and daily burn pattern.\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            dcc.Graph(id='landcover-time-series'),\n",
    "            dcc.Checklist(\n",
    "                id='landcover-selector',\n",
    "                options=[{'label': cat, 'value': cat} for cat in ['Forest', 'Cropland', 'Shrubland']],\n",
    "                value=['Forest', 'Cropland', 'Shrubland'],\n",
    "                inline=True,\n",
    "                style={'padding': '10px'}\n",
    "            )\n",
    "        ], style={'width': '48%', 'display': 'inline-block', 'verticalAlign': 'top'}),\n",
    "        \n",
    "        html.Div([\n",
    "            dcc.Graph(id='daily-burn-pattern')\n",
    "        ], style={'width': '48%', 'display': 'inline-block', 'verticalAlign': 'top'})\n",
    "    ])\n",
    "])\n",
    "\n",
    "# ----------------------- Callbacks -------------------------\n",
    "@app.callback(\n",
    "    [Output('province-map', 'figure'),\n",
    "     Output('map-status', 'children')],\n",
    "    [Input('year-dropdown', 'value')]\n",
    ")\n",
    "def update_map(selected_year):\n",
    "    \"\"\"\n",
    "    Update the map based on the selected year. Aggregates data if \"total\" is selected.\n",
    "\n",
    "    Args:\n",
    "        selected_year: Selected year from the dropdown or 'total'.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (Map figure, status message)\n",
    "    \"\"\"\n",
    "    if selected_year == 'total':\n",
    "        province_stats = {i: 0 for i in range(len(provinces))}\n",
    "        for year in range(START_YEAR, END_YEAR + 1):\n",
    "            file_path = BURNDATE_TEMPLATE.format(year=year)\n",
    "            if not os.path.exists(file_path):\n",
    "                continue\n",
    "            with rasterio.open(file_path) as src:\n",
    "                raster_crs = src.crs\n",
    "                affine = src.transform\n",
    "                provinces_reproj = provinces.to_crs(raster_crs)\n",
    "                burned_mask = src.read(1) > 0\n",
    "            stats = zonal_stats(\n",
    "                provinces_reproj,\n",
    "                burned_mask,\n",
    "                affine=affine,\n",
    "                stats=['sum'],\n",
    "                nodata=0,\n",
    "                all_touched=True,\n",
    "                geojson_out=True\n",
    "            )\n",
    "            for i, stat in enumerate(stats):\n",
    "                burned_val = stat['properties'].get('sum', 0)\n",
    "                province_stats[i] += burned_val if burned_val is not None else 0\n",
    "        gdf_stats = provinces.copy()\n",
    "        gdf_stats['burned_area'] = [province_stats[i] for i in range(len(provinces))]\n",
    "        gdf_stats['burned_area'] = gdf_stats['burned_area'] * (250**2) / 1e6\n",
    "        map_title = \"Total Burned Area (2001-2020)\"\n",
    "    else:\n",
    "        file_path = BURNDATE_TEMPLATE.format(year=selected_year)\n",
    "        if not os.path.exists(file_path):\n",
    "            return go.Figure(), \"Data not available for selected year.\"\n",
    "        with rasterio.open(file_path) as src:\n",
    "            raster_crs = src.crs\n",
    "            affine = src.transform\n",
    "            provinces_reproj = provinces.to_crs(raster_crs)\n",
    "            burned_mask = src.read(1) > 0\n",
    "        stats = zonal_stats(\n",
    "            provinces_reproj,\n",
    "            burned_mask,\n",
    "            affine=affine,\n",
    "            stats=['sum'],\n",
    "            nodata=0,\n",
    "            all_touched=True,\n",
    "            geojson_out=True\n",
    "        )\n",
    "        gdf_stats = gpd.GeoDataFrame.from_features(stats)\n",
    "        gdf_stats.crs = raster_crs\n",
    "        gdf_stats = gdf_stats.to_crs(provinces.crs)\n",
    "        gdf_stats['burned_area'] = gdf_stats['sum'].fillna(0) * (250**2) / 1e6\n",
    "        map_title = f\"Burned Area in {selected_year}\"\n",
    "    \n",
    "    fig = px.choropleth_mapbox(\n",
    "        gdf_stats,\n",
    "        geojson=gdf_stats.geometry,\n",
    "        locations=gdf_stats.index,\n",
    "        color='burned_area',\n",
    "        mapbox_style=\"carto-positron\",\n",
    "        zoom=4.5,\n",
    "        center={\"lat\": 36, \"lon\": 3},\n",
    "        opacity=0.8,\n",
    "        labels={'burned_area': 'Burned Area (km²)'},\n",
    "        color_continuous_scale='YlOrRd',\n",
    "        hover_data={'ADM1_EN': True, 'burned_area': ':.2f'}\n",
    "    )\n",
    "    fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0},\n",
    "                      title={'text': map_title, 'x': 0.5})\n",
    "    return fig, f\"Map displaying {map_title}.\"\n",
    "\n",
    "@app.callback(\n",
    "    [Output('landcover-time-series', 'figure'),\n",
    "     Output('daily-burn-pattern', 'figure')],\n",
    "    [Input('province-map', 'clickData'),\n",
    "     Input('landcover-selector', 'value')]\n",
    ")\n",
    "def update_charts(clickData, selected_categories):\n",
    "    \"\"\"\n",
    "    Update the land cover and daily burn pattern charts based on the selected province.\n",
    "    If no province is selected, global data is displayed.\n",
    "\n",
    "    Args:\n",
    "        clickData: Data from the map click event.\n",
    "        selected_categories: List of land cover groups to display.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (Land cover time series figure, Daily burn pattern figure)\n",
    "    \"\"\"\n",
    "    if clickData is None:\n",
    "        df_lc = landcover_df.copy()\n",
    "        df_bd = burndate_df.copy()\n",
    "        title_suffix = \" (All Provinces)\"\n",
    "    else:\n",
    "        province_index = clickData['points'][0]['location']\n",
    "        selected_province = provinces.iloc[int(province_index)]\n",
    "        province_name = selected_province.get('ADM1_EN', f\"Province {province_index}\")\n",
    "        title_suffix = f\" ({province_name})\"\n",
    "        df_lc = get_province_landcover(selected_province.geometry)\n",
    "        df_bd = get_province_burndates(selected_province.geometry)\n",
    "    \n",
    "    # Land Cover Bar Plot\n",
    "    if not df_lc.empty:\n",
    "        df_melted = df_lc.melt(id_vars='Year', value_vars=['Forest', 'Cropland', 'Shrubland'],\n",
    "                               var_name='Category', value_name='Burned Area')\n",
    "        df_melted = df_melted[df_melted['Category'].isin(selected_categories)]\n",
    "        fig_lc = px.bar(df_melted, x='Year', y='Burned Area', color='Category', barmode='group',\n",
    "                        labels={'Burned Area': 'Burned Area (km²)', 'Category': 'Land Cover Group'},\n",
    "                        template='plotly_white',\n",
    "                        title=\"Land Cover Burned Area\" + title_suffix)\n",
    "    else:\n",
    "        fig_lc = go.Figure()\n",
    "        fig_lc.update_layout(title=\"No land cover data available\" + title_suffix)\n",
    "    \n",
    "    # Daily Burn Pattern Bar Plot\n",
    "    if not df_bd.empty:\n",
    "        daily_counts = df_bd.groupby('day_of_year').size().reset_index(name='counts')\n",
    "        fig_bd = go.Figure()\n",
    "        fig_bd.add_trace(go.Bar(\n",
    "            x=daily_counts['day_of_year'],\n",
    "            y=daily_counts['counts'],\n",
    "            marker_color='#e74c3c',\n",
    "            name='Burn Frequency'\n",
    "        ))\n",
    "        fig_bd.update_layout(\n",
    "            title=\"Daily Burn Frequency\" + title_suffix,\n",
    "            xaxis_title='Day of Year',\n",
    "            yaxis_title='Number of Burned Pixels (250m)',\n",
    "            hovermode='x unified',\n",
    "            template='plotly_white',\n",
    "            showlegend=False\n",
    "        )\n",
    "    else:\n",
    "        fig_bd = go.Figure()\n",
    "        fig_bd.update_layout(title=\"No burn date data available\" + title_suffix)\n",
    "    \n",
    "    return fig_lc, fig_bd\n",
    "\n",
    "# ----------------------- Main Entry Point -------------------------\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main entry point for the Dash application.\n",
    "    \"\"\"\n",
    "    port = int(os.environ.get(\"PORT\", 8051))\n",
    "    app.run_server(debug=False, host='0.0.0.0', port=port)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e4fd47-d42c-4bea-9e50-73c98fa594a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
